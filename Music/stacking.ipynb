{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "import random, arff\n",
    "import os, sys, subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = os.listdir(\".\")\n",
    "#number of labels\n",
    "col = list(range(0, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the files\n",
    "test = pd.read_csv('Music_a_test1.arff',sep=',',header=None).iloc[:,col]\n",
    "BR   = pd.read_csv('BR-Music_a_test1.arff',sep=',',header=None).iloc[:,col]\n",
    "CC   = pd.read_csv('CC-Music_a_test1.arff',sep=',',header=None).iloc[:,col]\n",
    "CDN  = pd.read_csv('CDN-Music_a_test1.arff',sep=',',header=None).iloc[:,col]\n",
    "CDT  = pd.read_csv('CDT-Music_a_test1.arff',sep=',',header=None).iloc[:,col]\n",
    "CT   = pd.read_csv('CT-Music_a_test1.arff',sep=',',header=None).iloc[:,col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    clf_name = (BR,CC,CDN,CDT,CT,test)\n",
    "    for name in clf_name:\n",
    "        name.columns = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_cal(y_true, y_pred, print_all = False):\n",
    "    if(y_true.shape != y_pred.shape):\n",
    "        print(\"Wrong y_preds matrics!\")\n",
    "\n",
    "    real_pos = real_neg = pred_pos = pred_neg  = true_pos = true_neg = []\n",
    "\n",
    "    for i in range(y_true.shape[0]):\n",
    "        # real values - RP and RN\n",
    "        real_pos = np.asarray(np.append(real_pos,np.logical_and(y_true[i], y_true[i]).sum()), dtype=np.int64).reshape(-1,1)\n",
    "        real_neg = np.asarray(np.append(real_neg,np.logical_and(np.logical_not(y_true[i]),np.logical_not(y_true[i])).sum()), dtype=np.int64).reshape(-1,1)\n",
    "\n",
    "        # y_pred values - PP and PN\n",
    "        pred_pos = np.asarray(np.append(pred_pos,np.logical_and(y_pred[i], y_pred[i]).sum()),dtype=np.int64).reshape(-1,1)\n",
    "        pred_neg = np.asarray(np.append(pred_neg,np.logical_and(np.logical_not(y_pred[i]), np.logical_not(y_pred[i])).sum()),dtype=np.int64).reshape(-1,1)\n",
    "\n",
    "        # true labels - TP and TN\n",
    "        true_pos = np.asarray(np.append(true_pos,np.logical_and(y_true[i], y_pred[i]).sum()),dtype=np.int64).reshape(-1,1)\n",
    "        true_neg = np.asarray(np.append(true_neg,np.logical_and(np.logical_not(y_true[i]), np.logical_not(y_pred[i])).sum()),dtype=np.int64).reshape(-1,1)\n",
    "\n",
    "    if print_all:\n",
    "\t\t# if print_all = True - it prints RP, RN, PP, PN, TP and TN\n",
    "        result = np.concatenate((real_pos, real_neg, pred_pos, pred_neg, true_pos, true_neg), axis=1)\n",
    "        print(result)\n",
    "\n",
    "    return(real_pos, real_neg, pred_pos, pred_neg, true_pos, true_neg)\n",
    "\n",
    "#function to resolve divide by zero error and accept the value 0 when divided by 0\n",
    "def divideZero( value_a, value_b):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        result = np.true_divide( value_a, value_b )\n",
    "        result[ ~ np.isfinite( result )] = 0\n",
    "    return result\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    #return the accuracy - example based\n",
    "    real_pos, real_neg, pred_pos, pred_neg, true_pos, true_neg = pre_cal(y_true,y_pred)\n",
    "    score = (true_pos + true_neg)/(pred_pos + pred_neg)\n",
    "    score = np.mean(score)\n",
    "    return score\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    #return precision - example based\n",
    "    real_pos, real_neg, pred_pos, pred_neg, true_pos, true_neg = pre_cal(y_true,y_pred)\n",
    "    score = divideZero(true_pos, pred_pos)\n",
    "    score = np.mean(score)\n",
    "    return score\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    #return precision - example based\n",
    "    real_pos, real_neg, pred_pos, pred_neg, true_pos, true_neg = pre_cal(y_true,y_pred)\n",
    "    score = divideZero(true_pos, real_pos)\n",
    "    score = np.mean(score)\n",
    "    return score\n",
    "\n",
    "\n",
    "def fscore(y_true, y_pred,beta = 1):\n",
    "\t#return f(beta)score - example based : default beta value is 1\n",
    "    prec, rec = precision(y_true, y_pred), recall(y_true, y_pred)\n",
    "    beta_val = beta*beta\n",
    "    score = ((1+beta_val)*(prec*rec))/(beta_val*(prec+rec))\n",
    "    return score\n",
    "\n",
    "\n",
    "def hamloss(y_true, y_pred):\n",
    "\t#return hamming loss - example based\n",
    "    hamloss = list()\n",
    "    for i in range(y_true.shape[0]):\n",
    "        hamloss = np.asarray(np.append(hamloss,np.logical_xor(y_true[i], y_pred[i]).sum()), dtype=np.int64).reshape(-1,1)\n",
    "    score = (hamloss.sum())/((y_true.shape[0])*(y_true.shape[1]))\n",
    "    return score\n",
    "\n",
    "\n",
    "def subset(y_true, y_pred):\n",
    "\t#return subset accuracy - example based\n",
    "    subset_matrix = list()\n",
    "    for i in range(y_true.shape[0]):\n",
    "        subset_matrix = np.asarray(np.append(subset_matrix, np.array_equal(y_true[i],y_pred[i])), dtype=np.int64).reshape(-1,1)\n",
    "    score = (subset_matrix.sum())/((y_true.shape[0])*(y_true.shape[1]))\n",
    "    return score\n",
    "\n",
    "def zeroloss(y_true, y_pred):\n",
    "    #return new array with removed element having all zero in y_true\n",
    "    condition = list()\n",
    "    index = list()\n",
    "    for i in range(y_true.shape[0]):\n",
    "        new_true = new_pred = list()\n",
    "        condition = np.logical_and(y_true[i],y_true[i]).sum()\n",
    "        if (condition==0):\n",
    "            index = np.asarray(np.append(index,i), dtype = np.int64)\n",
    "\n",
    "        new_true = np.delete(y_true,index, axis = 0)\n",
    "        new_pred = np.delete(y_pred,index, axis = 0)\n",
    "    return new_true, new_pred\n",
    "\n",
    "def microprecision(y_true, y_pred):\n",
    "    #return micro-precision\n",
    "    real_pos, real_neg, pred_pos, pred_neg, true_pos, true_neg = pre_cal(y_true,y_pred)\n",
    "    score = true_pos.sum()/pred_pos.sum()\n",
    "    return score\n",
    "\n",
    "def microrecall(y_true, y_pred):\n",
    "    #return micro-recall\n",
    "    real_pos, real_neg, pred_pos, pred_neg, true_pos, true_neg = pre_cal(y_true,y_pred)\n",
    "    score = true_pos.sum()/real_pos.sum()\n",
    "    return score\n",
    "\n",
    "def microfscore(y_true, y_pred,beta = 1):\n",
    "    #return micro-fscore\n",
    "    prec, rec = microprecision(y_true, y_pred), microrecall(y_true, y_pred)\n",
    "    beta_val = beta*beta\n",
    "    score = ((1+beta_val)*(prec*rec))/(beta_val*(prec+rec))\n",
    "    return score\n",
    "\n",
    "def macroprecision(y_true, y_pred):\n",
    "    #return macro-precision\n",
    "    real_pos, real_neg, pred_pos, pred_neg, true_pos, true_neg = pre_cal(y_true,y_pred)\n",
    "    score = divideZero(true_pos, pred_pos)\n",
    "    return score\n",
    "\n",
    "def macrorecall(y_true, y_pred):\n",
    "    #return macro-recall\n",
    "    real_pos, real_neg, pred_pos, pred_neg, true_pos, true_neg = pre_cal(y_true,y_pred)\n",
    "    score = divideZero(true_pos, real_pos)\n",
    "    return score\n",
    "\n",
    "def macrofscore(y_true, y_pred,beta = 1):\n",
    "    #return macro-fscore\n",
    "    prec, rec = macroprecision(y_true, y_pred), macrorecall(y_true, y_pred)\n",
    "    beta_val = beta*beta\n",
    "    score = divideZero(((1+beta_val)*(prec*rec)),(beta_val*(prec+rec)))\n",
    "    score = np.mean(score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_all(np_test, np_pred, output):\n",
    "    value = list()\n",
    "    value.append(accuracy(np_test,np_pred))\n",
    "    value.append(precision(np_test,np_pred))\n",
    "    value.append(recall(np_test,np_pred))\n",
    "    value.append(fscore(np_test,np_pred))\n",
    "    value.append(hamloss(np_test,np_pred))\n",
    "    value.append(subset(np_test,np_pred))\n",
    "    value.append(microfscore(np_test,np_pred))\n",
    "    value.append(macrofscore(np_test,np_pred))\n",
    "    output.append(value)\n",
    "    if False:\n",
    "        print(\"Accuracy : {0:.4f}\".format(value[2]))\n",
    "        print(\"Precision: {0:.4f}\".format(value[3]))\n",
    "        print(\"Recall   : {0:.4f}\".format(value[4]))\n",
    "        print(\"F1-Score : {0:.4f}\".format(value[5]))\n",
    "        print(\"HammingL : {0:.4f}\".format(value[6]))\n",
    "        print(\"Subset   : {0:.4f}\".format(value[7]))\n",
    "        print(\"Micro - F1-Score : {0:.4f}\".format(value[8]))\n",
    "        print(\"Macro - F1-Score : {0:.4f}\".format(value[9]))\n",
    "        print(\"----------------------------------\")\n",
    "    del value\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_name = list()\n",
    "for x in range(len(col)):\n",
    "    label_name.append(pd.DataFrame(pd.concat([BR[x],CC[x],CDN[x],CDT[x],CT[x]], axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_name = list()\n",
    "for x in range(len(col)):\n",
    "    test_name.append(test[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, random_state= 42, shuffle= True) \n",
    "\n",
    "def implement_kfold(x,label_,test_):\n",
    "    output = list()\n",
    "    clf = LogisticRegression(C=1e5)\n",
    "    X = label_.values\n",
    "    y = test_.values\n",
    "    y.resize(len(y))\n",
    "    kf.get_n_splits(X)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        #test-train split for K- Fold \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        #train the clasifier\n",
    "        clf.fit(X_train,y_train)\n",
    "        #predict the result\n",
    "        y_pred = clf.predict(X_test)\n",
    "        if False:\n",
    "            print(\"-------------------------------\")\n",
    "            print(\"X_train: {}, y_train: {}\".format(len(X_train),len(y_train)))\n",
    "            print(\"X_test : {}, y_test : {}\".format(len(X_test),len(y_test)))\n",
    "            print(\"y_pred: {}\".format(len(y_pred)))\n",
    "            print(\"-------------------------------\")\n",
    "        y_test.resize(len(y_test),1)\n",
    "        y_pred.resize(len(y_pred),1)\n",
    "        #get the score\n",
    "        calculate_all(y_test,y_pred,output)\n",
    "    del clf\n",
    "    data = pd.DataFrame(output)\n",
    "    return(data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\abhishek verma\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:61: RuntimeWarning: invalid value encountered in double_scalars\n",
      "c:\\users\\abhishek verma\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:99: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    }
   ],
   "source": [
    "result = list()\n",
    "for x in range(len(col)):\n",
    "    result.append(implement_kfold(x,label_name[x],pd.DataFrame(test_name[x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f-score</th>\n",
       "      <th>hamloss</th>\n",
       "      <th>subset</th>\n",
       "      <th>microf</th>\n",
       "      <th>macrof</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.772692</td>\n",
       "      <td>0.186795</td>\n",
       "      <td>0.186795</td>\n",
       "      <td>0.186795</td>\n",
       "      <td>0.227308</td>\n",
       "      <td>0.772692</td>\n",
       "      <td>0.629194</td>\n",
       "      <td>0.186795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.692179</td>\n",
       "      <td>0.045641</td>\n",
       "      <td>0.045641</td>\n",
       "      <td>0.057051</td>\n",
       "      <td>0.307821</td>\n",
       "      <td>0.692179</td>\n",
       "      <td>0.270709</td>\n",
       "      <td>0.045641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.757308</td>\n",
       "      <td>0.344231</td>\n",
       "      <td>0.344231</td>\n",
       "      <td>0.344231</td>\n",
       "      <td>0.242692</td>\n",
       "      <td>0.757308</td>\n",
       "      <td>0.733157</td>\n",
       "      <td>0.344231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.847821</td>\n",
       "      <td>0.157051</td>\n",
       "      <td>0.157051</td>\n",
       "      <td>0.157051</td>\n",
       "      <td>0.152179</td>\n",
       "      <td>0.847821</td>\n",
       "      <td>0.669748</td>\n",
       "      <td>0.157051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.787692</td>\n",
       "      <td>0.106026</td>\n",
       "      <td>0.106026</td>\n",
       "      <td>0.106026</td>\n",
       "      <td>0.212308</td>\n",
       "      <td>0.787692</td>\n",
       "      <td>0.501212</td>\n",
       "      <td>0.106026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.732564</td>\n",
       "      <td>0.166154</td>\n",
       "      <td>0.166154</td>\n",
       "      <td>0.166154</td>\n",
       "      <td>0.267436</td>\n",
       "      <td>0.732564</td>\n",
       "      <td>0.502366</td>\n",
       "      <td>0.166154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision    recall   f-score   hamloss    subset    microf  \\\n",
       "0  0.772692   0.186795  0.186795  0.186795  0.227308  0.772692  0.629194   \n",
       "1  0.692179   0.045641  0.045641  0.057051  0.307821  0.692179  0.270709   \n",
       "2  0.757308   0.344231  0.344231  0.344231  0.242692  0.757308  0.733157   \n",
       "3  0.847821   0.157051  0.157051  0.157051  0.152179  0.847821  0.669748   \n",
       "4  0.787692   0.106026  0.106026  0.106026  0.212308  0.787692  0.501212   \n",
       "5  0.732564   0.166154  0.166154  0.166154  0.267436  0.732564  0.502366   \n",
       "\n",
       "     macrof  \n",
       "0  0.186795  \n",
       "1  0.045641  \n",
       "2  0.344231  \n",
       "3  0.157051  \n",
       "4  0.106026  \n",
       "5  0.166154  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column = ['accuracy','precision','recall','f-score','hamloss','subset','microf','macrof']\n",
    "df = pd.DataFrame(np.asarray(result), columns= column)\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('Stacking.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy     0.765043\n",
       "precision    0.167650\n",
       "recall       0.167650\n",
       "f-score      0.169551\n",
       "hamloss      0.234957\n",
       "subset       0.765043\n",
       "microf       0.551064\n",
       "macrof       0.167650\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
