{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "import random, arff\n",
    "import os, sys, subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = os.listdir(\".\")\n",
    "#number of labels\n",
    "col = list(range(0, 14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the files\n",
    "test = pd.read_csv('Yeast_a_test1.arff',sep=',',header=None).iloc[:,col]\n",
    "BR   = pd.read_csv('BR-Yeast_a_test1.arff',sep=',',header=None).iloc[:,col]\n",
    "CC   = pd.read_csv('CC-Yeast_a_test1.arff',sep=',',header=None).iloc[:,col]\n",
    "CDN  = pd.read_csv('CDN-Yeast_a_test1.arff',sep=',',header=None).iloc[:,col]\n",
    "CDT  = pd.read_csv('CDT-Yeast_a_test1.arff',sep=',',header=None).iloc[:,col]\n",
    "CT   = pd.read_csv('CT-Yeast_a_test1.arff',sep=',',header=None).iloc[:,col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    clf_name = (BR,CC,CDN,CDT,CT,test)\n",
    "    for name in clf_name:\n",
    "        name.columns = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_cal(y_true, y_pred, print_all = False):\n",
    "    if(y_true.shape != y_pred.shape):\n",
    "        print(\"Wrong y_preds matrics!\")\n",
    "\n",
    "    real_pos = real_neg = pred_pos = pred_neg  = true_pos = true_neg = []\n",
    "\n",
    "    for i in range(y_true.shape[0]):\n",
    "        # real values - RP and RN\n",
    "        real_pos = np.asarray(np.append(real_pos,np.logical_and(y_true[i], y_true[i]).sum()), dtype=np.int64).reshape(-1,1)\n",
    "        real_neg = np.asarray(np.append(real_neg,np.logical_and(np.logical_not(y_true[i]),np.logical_not(y_true[i])).sum()), dtype=np.int64).reshape(-1,1)\n",
    "\n",
    "        # y_pred values - PP and PN\n",
    "        pred_pos = np.asarray(np.append(pred_pos,np.logical_and(y_pred[i], y_pred[i]).sum()),dtype=np.int64).reshape(-1,1)\n",
    "        pred_neg = np.asarray(np.append(pred_neg,np.logical_and(np.logical_not(y_pred[i]), np.logical_not(y_pred[i])).sum()),dtype=np.int64).reshape(-1,1)\n",
    "\n",
    "        # true labels - TP and TN\n",
    "        true_pos = np.asarray(np.append(true_pos,np.logical_and(y_true[i], y_pred[i]).sum()),dtype=np.int64).reshape(-1,1)\n",
    "        true_neg = np.asarray(np.append(true_neg,np.logical_and(np.logical_not(y_true[i]), np.logical_not(y_pred[i])).sum()),dtype=np.int64).reshape(-1,1)\n",
    "\n",
    "    if print_all:\n",
    "\t\t# if print_all = True - it prints RP, RN, PP, PN, TP and TN\n",
    "        result = np.concatenate((real_pos, real_neg, pred_pos, pred_neg, true_pos, true_neg), axis=1)\n",
    "        print(result)\n",
    "\n",
    "    return(real_pos, real_neg, pred_pos, pred_neg, true_pos, true_neg)\n",
    "\n",
    "#function to resolve divide by zero error and accept the value 0 when divided by 0\n",
    "def divideZero( value_a, value_b):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        result = np.true_divide( value_a, value_b )\n",
    "        result[ ~ np.isfinite( result )] = 0\n",
    "    return result\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    #return the accuracy - example based\n",
    "    real_pos, real_neg, pred_pos, pred_neg, true_pos, true_neg = pre_cal(y_true,y_pred)\n",
    "    score = (true_pos + true_neg)/(pred_pos + pred_neg)\n",
    "    score = np.mean(score)\n",
    "    return score\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    #return precision - example based\n",
    "    real_pos, real_neg, pred_pos, pred_neg, true_pos, true_neg = pre_cal(y_true,y_pred)\n",
    "    score = divideZero(true_pos, pred_pos)\n",
    "    score = np.mean(score)\n",
    "    return score\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    #return precision - example based\n",
    "    real_pos, real_neg, pred_pos, pred_neg, true_pos, true_neg = pre_cal(y_true,y_pred)\n",
    "    score = divideZero(true_pos, real_pos)\n",
    "    score = np.mean(score)\n",
    "    return score\n",
    "\n",
    "\n",
    "def fscore(y_true, y_pred,beta = 1):\n",
    "\t#return f(beta)score - example based : default beta value is 1\n",
    "    prec, rec = precision(y_true, y_pred), recall(y_true, y_pred)\n",
    "    beta_val = beta*beta\n",
    "    score = ((1+beta_val)*(prec*rec))/(beta_val*(prec+rec))\n",
    "    return score\n",
    "\n",
    "\n",
    "def hamloss(y_true, y_pred):\n",
    "\t#return hamming loss - example based\n",
    "    hamloss = list()\n",
    "    for i in range(y_true.shape[0]):\n",
    "        hamloss = np.asarray(np.append(hamloss,np.logical_xor(y_true[i], y_pred[i]).sum()), dtype=np.int64).reshape(-1,1)\n",
    "    score = (hamloss.sum())/((y_true.shape[0])*(y_true.shape[1]))\n",
    "    return score\n",
    "\n",
    "\n",
    "def subset(y_true, y_pred):\n",
    "\t#return subset accuracy - example based\n",
    "    subset_matrix = list()\n",
    "    for i in range(y_true.shape[0]):\n",
    "        subset_matrix = np.asarray(np.append(subset_matrix, np.array_equal(y_true[i],y_pred[i])), dtype=np.int64).reshape(-1,1)\n",
    "    score = (subset_matrix.sum())/((y_true.shape[0])*(y_true.shape[1]))\n",
    "    return score\n",
    "\n",
    "def zeroloss(y_true, y_pred):\n",
    "    #return new array with removed element having all zero in y_true\n",
    "    condition = list()\n",
    "    index = list()\n",
    "    for i in range(y_true.shape[0]):\n",
    "        new_true = new_pred = list()\n",
    "        condition = np.logical_and(y_true[i],y_true[i]).sum()\n",
    "        if (condition==0):\n",
    "            index = np.asarray(np.append(index,i), dtype = np.int64)\n",
    "\n",
    "        new_true = np.delete(y_true,index, axis = 0)\n",
    "        new_pred = np.delete(y_pred,index, axis = 0)\n",
    "    return new_true, new_pred\n",
    "\n",
    "def microprecision(y_true, y_pred):\n",
    "    #return micro-precision\n",
    "    real_pos, real_neg, pred_pos, pred_neg, true_pos, true_neg = pre_cal(y_true,y_pred)\n",
    "    score = true_pos.sum()/pred_pos.sum()\n",
    "    return score\n",
    "\n",
    "def microrecall(y_true, y_pred):\n",
    "    #return micro-recall\n",
    "    real_pos, real_neg, pred_pos, pred_neg, true_pos, true_neg = pre_cal(y_true,y_pred)\n",
    "    score = true_pos.sum()/real_pos.sum()\n",
    "    return score\n",
    "\n",
    "def microfscore(y_true, y_pred,beta = 1):\n",
    "    #return micro-fscore\n",
    "    prec, rec = microprecision(y_true, y_pred), microrecall(y_true, y_pred)\n",
    "    beta_val = beta*beta\n",
    "    score = ((1+beta_val)*(prec*rec))/(beta_val*(prec+rec))\n",
    "    return score\n",
    "\n",
    "def macroprecision(y_true, y_pred):\n",
    "    #return macro-precision\n",
    "    real_pos, real_neg, pred_pos, pred_neg, true_pos, true_neg = pre_cal(y_true,y_pred)\n",
    "    score = divideZero(true_pos, pred_pos)\n",
    "    return score\n",
    "\n",
    "def macrorecall(y_true, y_pred):\n",
    "    #return macro-recall\n",
    "    real_pos, real_neg, pred_pos, pred_neg, true_pos, true_neg = pre_cal(y_true,y_pred)\n",
    "    score = divideZero(true_pos, real_pos)\n",
    "    return score\n",
    "\n",
    "def macrofscore(y_true, y_pred,beta = 1):\n",
    "    #return macro-fscore\n",
    "    prec, rec = macroprecision(y_true, y_pred), macrorecall(y_true, y_pred)\n",
    "    beta_val = beta*beta\n",
    "    score = divideZero(((1+beta_val)*(prec*rec)),(beta_val*(prec+rec)))\n",
    "    score = np.mean(score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_all(np_test, np_pred, output):\n",
    "    value = list()\n",
    "    value.append(accuracy(np_test,np_pred))\n",
    "    value.append(precision(np_test,np_pred))\n",
    "    value.append(recall(np_test,np_pred))\n",
    "    value.append(fscore(np_test,np_pred))\n",
    "    value.append(hamloss(np_test,np_pred))\n",
    "    value.append(subset(np_test,np_pred))\n",
    "    value.append(microfscore(np_test,np_pred))\n",
    "    value.append(macrofscore(np_test,np_pred))\n",
    "    output.append(value)\n",
    "    if False:\n",
    "        print(\"Accuracy : {0:.4f}\".format(value[2]))\n",
    "        print(\"Precision: {0:.4f}\".format(value[3]))\n",
    "        print(\"Recall   : {0:.4f}\".format(value[4]))\n",
    "        print(\"F1-Score : {0:.4f}\".format(value[5]))\n",
    "        print(\"HammingL : {0:.4f}\".format(value[6]))\n",
    "        print(\"Subset   : {0:.4f}\".format(value[7]))\n",
    "        print(\"Micro - F1-Score : {0:.4f}\".format(value[8]))\n",
    "        print(\"Macro - F1-Score : {0:.4f}\".format(value[9]))\n",
    "        print(\"----------------------------------\")\n",
    "    del value\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_name = list()\n",
    "for x in range(len(col)):\n",
    "    label_name.append(pd.DataFrame(pd.concat([BR[x],CC[x],CDN[x],CDT[x],CT[x]], axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_name = list()\n",
    "for x in range(len(col)):\n",
    "    test_name.append(test[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, random_state= 42, shuffle= True) \n",
    "\n",
    "def implement_kfold(x,label_,test_):\n",
    "    output = list()\n",
    "    clf = LogisticRegression(C=1e5)\n",
    "    X = label_.values\n",
    "    y = test_.values\n",
    "    y.resize(len(y))\n",
    "    kf.get_n_splits(X)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        #test-train split for K- Fold \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "   \n",
    "        #train the clasifier\n",
    "        clf.fit(X_train,y_train)\n",
    "        #predict the result\n",
    "        y_pred = clf.predict(X_test)\n",
    "        if False:\n",
    "            print(\"-------------------------------\")\n",
    "            print(\"X_train: {}, y_train: {}\".format(len(X_train),len(y_train)))\n",
    "            print(\"X_test : {}, y_test : {}\".format(len(X_test),len(y_test)))\n",
    "            print(\"y_pred: {}\".format(len(y_pred)))\n",
    "            print(\"-------------------------------\")\n",
    "        y_test.resize(len(y_test),1)\n",
    "        y_pred.resize(len(y_pred),1)\n",
    "        #get the score\n",
    "        calculate_all(y_test,y_pred,output)\n",
    "    del clf\n",
    "    data = pd.DataFrame(output)\n",
    "    return(data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#implement_kfold(1,label_name[1],pd.DataFrame(test_name[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\abhishek verma\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:61: RuntimeWarning: invalid value encountered in double_scalars\n",
      "c:\\users\\abhishek verma\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:99: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "c:\\users\\abhishek verma\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:112: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "result = list()\n",
    "for x in range(len(col)):\n",
    "    result.append(implement_kfold(x,label_name[x],pd.DataFrame(test_name[x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f-score</th>\n",
       "      <th>hamloss</th>\n",
       "      <th>subset</th>\n",
       "      <th>microf</th>\n",
       "      <th>macrof</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.718457</td>\n",
       "      <td>0.101764</td>\n",
       "      <td>0.101764</td>\n",
       "      <td>0.101764</td>\n",
       "      <td>0.281543</td>\n",
       "      <td>0.718457</td>\n",
       "      <td>0.417811</td>\n",
       "      <td>0.101764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.595583</td>\n",
       "      <td>0.138969</td>\n",
       "      <td>0.138969</td>\n",
       "      <td>0.138969</td>\n",
       "      <td>0.404417</td>\n",
       "      <td>0.595583</td>\n",
       "      <td>0.406133</td>\n",
       "      <td>0.138969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.670033</td>\n",
       "      <td>0.224576</td>\n",
       "      <td>0.224576</td>\n",
       "      <td>0.224576</td>\n",
       "      <td>0.329967</td>\n",
       "      <td>0.670033</td>\n",
       "      <td>0.578121</td>\n",
       "      <td>0.224576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.687294</td>\n",
       "      <td>0.168752</td>\n",
       "      <td>0.168752</td>\n",
       "      <td>0.168752</td>\n",
       "      <td>0.312706</td>\n",
       "      <td>0.687294</td>\n",
       "      <td>0.519194</td>\n",
       "      <td>0.168752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.736960</td>\n",
       "      <td>0.095552</td>\n",
       "      <td>0.095552</td>\n",
       "      <td>0.095552</td>\n",
       "      <td>0.263040</td>\n",
       "      <td>0.736960</td>\n",
       "      <td>0.418581</td>\n",
       "      <td>0.095552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.785362</td>\n",
       "      <td>0.031002</td>\n",
       "      <td>0.031002</td>\n",
       "      <td>0.031002</td>\n",
       "      <td>0.214638</td>\n",
       "      <td>0.785362</td>\n",
       "      <td>0.220626</td>\n",
       "      <td>0.031002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.837451</td>\n",
       "      <td>0.023564</td>\n",
       "      <td>0.023564</td>\n",
       "      <td>0.023564</td>\n",
       "      <td>0.162549</td>\n",
       "      <td>0.837451</td>\n",
       "      <td>0.224790</td>\n",
       "      <td>0.023564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.798988</td>\n",
       "      <td>0.022322</td>\n",
       "      <td>0.022322</td>\n",
       "      <td>0.022322</td>\n",
       "      <td>0.201012</td>\n",
       "      <td>0.798988</td>\n",
       "      <td>0.183088</td>\n",
       "      <td>0.022322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.916847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083153</td>\n",
       "      <td>0.916847</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.885837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.114163</td>\n",
       "      <td>0.885837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.874672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.125328</td>\n",
       "      <td>0.874672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.727053</td>\n",
       "      <td>0.717115</td>\n",
       "      <td>0.717115</td>\n",
       "      <td>0.717115</td>\n",
       "      <td>0.272947</td>\n",
       "      <td>0.727053</td>\n",
       "      <td>0.839951</td>\n",
       "      <td>0.717115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.722077</td>\n",
       "      <td>0.722077</td>\n",
       "      <td>0.722077</td>\n",
       "      <td>0.722077</td>\n",
       "      <td>0.277923</td>\n",
       "      <td>0.722077</td>\n",
       "      <td>0.838419</td>\n",
       "      <td>0.722077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.980170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019830</td>\n",
       "      <td>0.980170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  precision    recall   f-score   hamloss    subset    microf  \\\n",
       "0   0.718457   0.101764  0.101764  0.101764  0.281543  0.718457  0.417811   \n",
       "1   0.595583   0.138969  0.138969  0.138969  0.404417  0.595583  0.406133   \n",
       "2   0.670033   0.224576  0.224576  0.224576  0.329967  0.670033  0.578121   \n",
       "3   0.687294   0.168752  0.168752  0.168752  0.312706  0.687294  0.519194   \n",
       "4   0.736960   0.095552  0.095552  0.095552  0.263040  0.736960  0.418581   \n",
       "5   0.785362   0.031002  0.031002  0.031002  0.214638  0.785362  0.220626   \n",
       "6   0.837451   0.023564  0.023564  0.023564  0.162549  0.837451  0.224790   \n",
       "7   0.798988   0.022322  0.022322  0.022322  0.201012  0.798988  0.183088   \n",
       "8   0.916847   0.000000  0.000000       NaN  0.083153  0.916847       NaN   \n",
       "9   0.885837   0.000000  0.000000       NaN  0.114163  0.885837       NaN   \n",
       "10  0.874672   0.000000  0.000000       NaN  0.125328  0.874672       NaN   \n",
       "11  0.727053   0.717115  0.717115  0.717115  0.272947  0.727053  0.839951   \n",
       "12  0.722077   0.722077  0.722077  0.722077  0.277923  0.722077  0.838419   \n",
       "13  0.980170   0.000000  0.000000       NaN  0.019830  0.980170       NaN   \n",
       "\n",
       "      macrof  \n",
       "0   0.101764  \n",
       "1   0.138969  \n",
       "2   0.224576  \n",
       "3   0.168752  \n",
       "4   0.095552  \n",
       "5   0.031002  \n",
       "6   0.023564  \n",
       "7   0.022322  \n",
       "8   0.000000  \n",
       "9   0.000000  \n",
       "10  0.000000  \n",
       "11  0.717115  \n",
       "12  0.722077  \n",
       "13  0.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column = ['accuracy','precision','recall','f-score','hamloss','subset','microf','macrof']\n",
    "df = pd.DataFrame(np.asarray(result), columns= column)\n",
    "df.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('Stacking.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy     0.781199\n",
       "precision    0.160407\n",
       "recall       0.160407\n",
       "f-score      0.224569\n",
       "hamloss      0.218801\n",
       "subset       0.781199\n",
       "microf       0.464671\n",
       "macrof       0.160407\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
